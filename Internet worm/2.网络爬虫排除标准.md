

### 网络爬虫的尺寸
![avatar](E:/學習記錄/Python学习之路/images/网络爬虫的尺寸.png)

### 网络爬虫引发的问题
- 性能骚扰
    - Web服务器默认接收人类访问，受限于编写水平和目的，网络爬虫将会为Web服务器带来巨大的资源开销
- 法律风险
    - 服务器上的数据有产权归属，网络爬虫获取数据后牟利将带来法律风险
- 隐私泄露
    - 网络爬虫可能具备突破简单访问控制的能力，获得被保护数据，从而泄露个人隐私

### 网络爬虫的限制
- 来源审查：判断User‐Agent进行限制
    - 检查来访HTTP协议头的User‐Agent域，只响应浏览器或友好爬虫的访问
- 发布公告：Robots协议
    - 告知所有爬虫网站的爬取策略，要求爬虫遵守
- Robots协议：Robots Exclusion Standard,网络爬虫排除标准
    + 作用：网站告知网络爬虫哪些页面可以抓取，哪些不行
    + 形式：在网站根目录下的robots.txt文件
    + 使用：自动或人工识别robots.txt，再进行内容爬取
    + 约束性：Robots协议是建议而非约束，网络爬虫可以不遵守，但存在法律风险
```python
eg: 京东的Robots协议 https://www.jd.com/robots.txt
User‐agent: * 
Disallow: /?* 
Disallow: /pop/*.html 
Disallow: /pinpai/*.html?* 
User‐agent: EtaoSpider
Disallow: / 
User‐agent: HuihuiSpider
Disallow: / 
User‐agent: GwdangSpider
Disallow: / 
User‐agent: WochachaSpider
Disallow: /

# 注释 *代表所有，/代表根目录
# User‐agent: * 
# Disallow: /
```
